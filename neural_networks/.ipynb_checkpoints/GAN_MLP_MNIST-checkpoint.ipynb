{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load MNIST Data\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "plt.imshow(x_train[4], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "-1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "X_train = np.vstack((x_train, x_test))\n",
    "X_train = X_train.reshape((-1, 784))\n",
    "print(X_train.shape)\n",
    "\n",
    "# Normalize data to range [-1, 1]\n",
    "X_train = (X_train.astype('float32') - 127.5) / 127.5\n",
    "print(X_train.min(), X_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "HALF_BATCH = 128\n",
    "NO_OF_BATCHES = int(X_train.shape[0] / BATCH_SIZE)\n",
    "\n",
    "NOISE_DIM = 100  # Upsample this into 784 DIM vector\n",
    "adam = Adam(lr=1e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 784)               803600    \n",
      "=================================================================\n",
      "Total params: 1,486,352\n",
      "Trainable params: 1,486,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Generator \n",
    "# Input- Noise(DIM 100) Output- Image(DIM 784)\n",
    "generator = Sequential()\n",
    "generator.add(Dense(256, input_shape=(NOISE_DIM, )))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "generator.add(Dense(512))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "generator.add(Dense(1024))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "generator.add(Dense(784, activation='tanh'))\n",
    "\n",
    "generator.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                4112      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 537,377\n",
      "Trainable params: 537,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Discriminator \n",
    "# Input- Image(DIM 784)  Output- Class(DIM 1)\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Dense(512, input_shape=(784, )))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dense(256))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dense(16))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "discriminator.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 784)               1486352   \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 537377    \n",
      "=================================================================\n",
      "Total params: 2,023,729\n",
      "Trainable params: 1,486,352\n",
      "Non-trainable params: 537,377\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GAN Training Step-2\n",
    "discriminator.trainable = False\n",
    "gan_input = Input(shape=(NOISE_DIM, ))\n",
    "gen_img = generator(gan_input)\n",
    "gan_output = discriminator(gen_img)\n",
    "\n",
    "model = Model(gan_input, gan_output)\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(epoch, samples = 100):\n",
    "    noise = np.random.normal(0, 1, size=(samples, NOISE_DIM))\n",
    "    pred_imgs = generator.predict(noise)\n",
    "    pred_imgs.reshape((-1, 28, 28))\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(samples):\n",
    "        plt.subplot(10, 10, i+1)\n",
    "        plt.imshow(pred_imgs[i], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.save_fig(\"images/gan_pred_imgs_{0}.png\".format(epoch+1))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\goura\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": " Error while reading resource variable _AnonymousVar21 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/_AnonymousVar21/class tensorflow::Var does not exist.\n\t [[node mul_1/ReadVariableOp (defined at c:\\users\\goura\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_1362]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4878e0cfa696>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mfake_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHALF_BATCH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0md_loss_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_imgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0md_loss_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_imgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mepoch_d_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0md_loss_real\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0md_loss_fake\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\goura\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\goura\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\goura\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\goura\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\goura\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\goura\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\goura\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32mc:\\users\\goura\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m:  Error while reading resource variable _AnonymousVar21 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/_AnonymousVar21/class tensorflow::Var does not exist.\n\t [[node mul_1/ReadVariableOp (defined at c:\\users\\goura\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_1362]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "dis_loss = []\n",
    "gen_loss = []\n",
    "\n",
    "for epoch in range(TOTAL_EPOCHS):\n",
    "    epoch_d_loss = 0.\n",
    "    epoch_g_loss = 0.\n",
    "    \n",
    "    # Mini batch SGD\n",
    "    for step in range(NO_OF_BATCHES):\n",
    "        # Step-1 Discriminator training\n",
    "        # 50% Real data + 50% Fake data\n",
    "        \n",
    "        # Real data X\n",
    "        idxs = np.random.randint(0, X_train.shape[0], HALF_BATCH)\n",
    "        real_imgs = X_train[idxs]\n",
    "        \n",
    "        # Fake data X\n",
    "        noise = np.random.normal(0, 1, size=(HALF_BATCH, NOISE_DIM))\n",
    "        fake_imgs = generator.predict(noise)\n",
    "        \n",
    "        # Labels\n",
    "        real_y = np.ones((HALF_BATCH, 1)) * 0.9  # One sided label smoothing\n",
    "        fake_y = np.zeros((HALF_BATCH, 1))\n",
    "        \n",
    "        d_loss_real = discriminator.train_on_batch(real_imgs, real_y)\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_imgs, fake_y)\n",
    "        epoch_d_loss += 0.5*d_loss_real + 0.5*d_loss_fake\n",
    "        \n",
    "        # Generator Training (considering Frozen Discriminator)\n",
    "        noise = np.random.normal(0, 1, size=(BATCH_SIZE, NOISE_DIM))\n",
    "        ground_truth_y = np.ones((BATCH_SIZE, 1))\n",
    "        g_loss = model.train_on_batch(noise, ground_truth_y)\n",
    "        epoch_g_loss += g_loss\n",
    "        \n",
    "    dis_loss.append(epoch_d_loss/NO_OF_BACTHES)\n",
    "    gen_loss.append(epoch_g_loss/NO_OF_BACTHES)\n",
    "    \n",
    "    print(\"Epoch %d - Dis. loss- %.4f, Gen. Loss- &.4f\"%(\n",
    "            (epoch+1), epoch_d_loss/NO_OF_BACTHES, epoch_d_loss/NO_OF_BACTHES))\n",
    "    \n",
    "    if (epoch+1)%5 == 0:\n",
    "        generator.save('model_gan_gen_{0}.h5'.format(epoch+1))\n",
    "        save_images(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Losses\n",
    "plt.plot(dis_loss, label='Dis')\n",
    "plt.plot(gen_loss, label='Gen')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
